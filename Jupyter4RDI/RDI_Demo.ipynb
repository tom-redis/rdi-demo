{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redis Data Integration (RDI)\n",
    "Redis Enterprise feature that helps users ingest data in near real-time.\n",
    "## RDI currently supports 2 scenarios:\n",
    "- ### Data Ingest\n",
    "![diagram of ingest feature](img/ingest.png)\n",
    "- ### Write-behind \n",
    "(Note, Write-behind is currently in public preview.)\n",
    "![diagram of write-behind](img/write-behind.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suported Sources for Ingest\n",
    "- Oracle\n",
    "- MariaDB\n",
    "- MongoDB\n",
    "- MySQL\n",
    "- Percona XtraDB\n",
    "- Postgres\n",
    "- SQL Server\n",
    "- Cassandra\n",
    "- Datastx Cassandra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported targets (write-behind) \n",
    "- Oracle\n",
    "- MariaDB\n",
    "- MySQL\n",
    "- Postgres\n",
    "- SQL Server\n",
    "- Cassandra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDI Demo Environment\n",
    "![demo environment schematic](img/topology.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingest (Change Data Capture) Demo\n",
    "**Here's the script to continually generate semi-random data and `INSERT` it into Postgres.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "DB_HOST = \"postgresql\"\n",
    "DB_PORT = 5432\n",
    "DB_NAME = \"chinook\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"A script to generate and insert random track data into the 'Track' table of the Chinook database.\n",
    "\n",
    "    This script connects to the Chinook database and continuously inserts new track records\n",
    "    with random data into the 'Track' table. It uses a CSV file containing track names and composers\n",
    "    and generates random values for other track attributes such as genre, milliseconds, bytes, and unit price.\n",
    "    \"\"\"\n",
    "    # read chinook track data from CSV\n",
    "    track_df = pd.read_csv(\"track.csv\", usecols=[\"Name\", \"Composer\"])\n",
    "\n",
    "    # connect to database\n",
    "    print(\"connecting to DB\")\n",
    "    engine = create_engine(f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "    conn = engine.connect()\n",
    "\n",
    "    # fetch largest track id\n",
    "    res = conn.execute(\"\"\"SELECT COALESCE(MAX(\"TrackId\"), 0) FROM \"Track\" \"\"\").fetchall()\n",
    "    track_id = res[0][0]\n",
    "\n",
    "    while True:\n",
    "        track_rand_id = random.randrange(2, 3000)\n",
    "        track_name = track_df.iloc[track_rand_id, 0]\n",
    "        track_genre = random.randrange(1, 5)\n",
    "        track_composer = track_df.iloc[track_rand_id, 1]\n",
    "        track_milliseconds = random.randrange(100000, 300000)\n",
    "        track_bytes = random.randrange(100000, 500000)\n",
    "        track_id += 1\n",
    "\n",
    "        insert_stmt = \"\"\"INSERT INTO public.\"Track\"\n",
    "                (\"TrackId\", \"Name\", \"AlbumId\", \"MediaTypeId\", \"GenreId\", \"Composer\", \"Milliseconds\", \"Bytes\", \"UnitPrice\")\n",
    "                VALUES (%s, %s, 1, 1, %s, %s, %s, %s, 0.99)\"\"\"\n",
    "        conn.execute(insert_stmt, (track_id, track_name, track_genre, track_composer, track_milliseconds, track_bytes))\n",
    "\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(random.randint(100, 500)/1000)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We'll use the RDI CLI to deploy.**\n",
    "\n",
    "![command line screenshot of the deploy](img/redis_di_deploy.png)\n",
    "\n",
    "`redis-di deploy --rdi-host re-n1 --rdi-port 12001 --rdi-password redislabs --dir redis_di_config`\n",
    "1. `redis-di` : command line tool to manage & configure Redis Data Integration\n",
    "2. `deploy` : This command deploys the RDI configurations.\n",
    "3. The connection:\\\n",
    "  `--rdi-host re-n1`\\\n",
    "  `--rdi-port 12001`\\\n",
    "  `--rdi-password redislabs`\n",
    "4. `--dir redis_di_config` : Directory containing RDI configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Behind (caching) Demo\n",
    "**We'll use the RDI CLI to deploy this too, but with different configurations.**\n",
    "![RDI configuration step](img/redis-di-config.jpg)\n",
    "1. We go to the directory that has our configuration.\n",
    "`cd redis_di_wb_config`\\\n",
    "This is *in lieu of* specifying the --dir like we did above.\n",
    "2. Run the configuration.\\\n",
    "`redis-di configure --rdi-host re-n1 --rdi-port 12000`\n",
    "3. Use the CLI to deploy like before.\\\n",
    "![RDI wb deployment step](img/redis-di-deploy.jpg)\n",
    "`redis-di deploy --rdi-host re-n1 --rdi-port 12000 --rdi-password \"\"`\n",
    "- `redis-di` : command line tool to manage & configure Redis Data Integration\n",
    "- `deploy` : This command deploys the RDI configurations.\n",
    "- The connection:\\\n",
    "  `--rdi-host re-n1`\\\n",
    "  `--rdi-port 12000`\\\n",
    "  `--rdi-password \"\"` (empty string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2023, Redis Inc., All rights reserved."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
